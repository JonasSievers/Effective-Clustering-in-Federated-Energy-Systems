{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *\n",
    "from utils.attackhandler import *\n",
    "\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.path.normpath(os.path.dirname(os.path.dirname(os.getcwd()))), 'data/3final_data/Final_Energy_dataset.csv')\n",
    "cwd = os.path.normpath(os.getcwd())\n",
    "use_sin_cos_features = True\n",
    "\n",
    "# User indices based on clusters\n",
    "user_indices = [16, 24] # Cluster 2: [16,24] / Cluster 4: [1, 11, 12, 27] / Cluster 10: [2, 4, 6, 9, 10, 14, 15, 18, 25, 30]\n",
    "\n",
    "# Data processing parameters\n",
    "sequence_length = 49\n",
    "batch_size = 16\n",
    "\n",
    "# Initialize necessary objects\n",
    "dh = Datahandler()\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading and preparing data...\")\n",
    "df_array = load_and_prepare_data(file_path, user_indices, columns_filter_prefix=\"load\")\n",
    "\n",
    "# Apply sine and cosine transformations if the flag is set to True\n",
    "if use_sin_cos_features:\n",
    "    for i in range(len(df_array)):\n",
    "        df_array[i] = create_sin_cos_features(df_array[i])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "print(\"Splitting data into train, validation, and test sets...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(df_array, sequence_length, batch_size, dh)\n",
    "\n",
    "\n",
    "X_train_raw = X_train\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()]\n",
    "callbacks = get_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Attack\n",
    "\n",
    "#NORMAL DISTRIBUTION - Scale 1\n",
    "attack = \"FL_Load_noBACKDOOR_noBACKDOORNoise\"\n",
    "X_train = copy.deepcopy(X_train_raw)\n",
    "#X_train = backdoor_attack_at_time(X_train, noise_scale=1.0)\n",
    "\n",
    "plot_impact_of_attack_noise(X_train_raw, X_train, user=\"user1\", features=True)\n",
    "\n",
    "#Run Tests\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "aggregated_results, all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (f\"{attack}_aggregated_results\", aggregated_results), \n",
    "    (f\"{attack}_all_results\", all_results)], folder_name=\"results/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
