{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Effective-Clustering-in-Federated-Energy-Systems\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Effective-Clustering-in-Federated-Energy-Systems\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Effective-Clustering-in-Federated-Energy-Systems\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Effective-Clustering-in-Federated-Energy-Systems\\.venv\\lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.federatedAggregation import FederatedAggregation\n",
    "from utils.reinforcementLearningHelper import *\n",
    "from utils.federatedLearningHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 / State Space: 40 / Action Space: 1 / Upper bound: 2.3\n"
     ]
    }
   ],
   "source": [
    "#Setup Environments of selected buildings for training, evaluation, and testing\n",
    "\n",
    "environments, observation_spec, action_spec  = setup_energymanagement_environments(num_buildings=30, ecoPriority=1)\n",
    "\n",
    "#Check environment setup\n",
    "print(\n",
    "    \"Batch size:\", environments[\"train\"][f\"building_1\"].batch_size, \n",
    "    \"/ State Space: {} / Action Space: {}\".format(observation_spec.shape[0], action_spec.shape[0]),\n",
    "    \"/ Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 4,  6,  7,  8,  9, 10, 13, 17, 18, 20, 21, 25, 27, 29, 30],\n",
       "       dtype=int64),\n",
       " 1: array([ 1, 11, 12, 16, 19, 24], dtype=int64),\n",
       " 2: array([ 2,  3,  5, 14, 15, 22, 23, 26, 28], dtype=int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameter\n",
    "num_clusters = 3\n",
    "\n",
    "clustered_buildings = prosumption_clustered_buildings(num_clusters)\n",
    "clustered_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Agent networks\n",
    "federated_rounds = 3\n",
    "batch_size = 128\n",
    "replay_buffer_capacity = 20000 #-> only <18.000 samples per dataset\n",
    "initial_collect_steps = 2000 #2000\n",
    "collect_steps_per_iteration = 30 \n",
    "num_iterations = 10000 #10000\n",
    "eval_interval = num_iterations-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Effective-Clustering-in-Federated-Energy-Systems\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FEDERATED LEARNING - Initalization Round 0\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "#Initalize a global model for each Cluster of similar buildings\n",
    "for cluster in range(num_clusters):\n",
    "        \n",
    "        # 1. Build global agent per cluster\n",
    "        first_building_in_cluster = clustered_buildings[cluster][0]\n",
    "        global_ddpg_agent, global_eval_policy, global_collect_policy = initialize_ddpg_agent(\n",
    "                observation_spec=observation_spec, action_spec=action_spec, global_step=global_step, environments=environments,\n",
    "                )\n",
    "\n",
    "        # 2. Initially store weights\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/ddpg/cluster_{cluster}/FLround{0}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        save_ddpg_weights(global_ddpg_agent, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDERATED LEARNING - Model training for multiple Rounds\n",
    "\n",
    "#For each federated round and cluster\n",
    "for federated_round  in range(federated_rounds):\n",
    "    for cluster_number, buildings_in_cluster in clustered_buildings.items():\n",
    "\n",
    "        #Iterate through the buildings per cluster\n",
    "        print(f\"Cluster {cluster_number}: Buildings {buildings_in_cluster} Federated round ---\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "        local_storage = {\n",
    "            \"actor_weights\": [], \"critic_weights\": [], \"target_actor_weights\": [], \"target_critic_weights\": [],\"performance_metrics\": []\n",
    "            }\n",
    "        \n",
    "        for building_index in buildings_in_cluster:\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "            \n",
    "            #1. Initalize local agent\n",
    "            local_ddpg_agent, local_eval_policy, local_collect_policy = initialize_ddpg_agent(\n",
    "                observation_spec = observation_spec, action_spec = action_spec,\n",
    "                global_step = global_step, environments = environments,\n",
    "                )\n",
    "            \n",
    "            #2. Set global weights of this training round to agent (loads the weights of last training)\n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/ddpg/cluster_{cluster_number}/FLround{federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            local_ddpg_agent = set_weights_to_ddpg_agent(local_ddpg_agent, model_dir)\n",
    "            \n",
    "            #3. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            local_iterator, local_collect_driver, local_time_step, local_policy_state = setup_rl_training_pipeline(\n",
    "                local_ddpg_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,\n",
    "                local_collect_policy, initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #4. Train, evaluate agent and store weights\n",
    "            local_ddpg_agent, local_storage = local_agent_training_and_evaluation(\n",
    "                local_iterator, local_collect_driver, local_time_step, local_policy_state, global_step, \n",
    "                local_ddpg_agent, local_eval_policy, local_storage, building_index, num_iterations, environments, agent_type=\"ddpg\"\n",
    "                )           \n",
    "\n",
    "        # Performe Federated aggregation\n",
    "        average_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"actor_weights\"], local_storage[\"performance_metrics\"])\n",
    "        average_critic_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"critic_weights\"], local_storage[\"performance_metrics\"]) \n",
    "        average_target_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"target_actor_weights\"], local_storage[\"performance_metrics\"]) \n",
    "        average_target_critic_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"target_critic_weights\"], local_storage[\"performance_metrics\"])    \n",
    "        \n",
    "        #Save federated weights for next round (Round + 1)\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/ddpg/cluster_{cluster_number}/FLround{federated_round+1}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        save_federated_ddpg_weights(model_dir, average_actor_weights, average_critic_weights, average_target_actor_weights, average_target_critic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL REFITTING AND EVALUATION\n",
    "\n",
    "best_federated_round = 3\n",
    "num_rounds=3\n",
    "num_test_iterations = 1\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Building', 'Total Profit'])\n",
    "\n",
    "for cluster_number, buildings_in_cluster in clustered_buildings.items():\n",
    "    for building_index in buildings_in_cluster:\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            print(\"Cluster: \", cluster_number, \" - Building: \", building_index, \" - round: \", round)\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "            #1. Initalize local agent\n",
    "            tf_ddpg_agent, eval_policy, collect_policy = initialize_ddpg_agent(\n",
    "                observation_spec = observation_spec, action_spec = action_spec,\n",
    "                global_step = global_step, environments = environments,\n",
    "                )\n",
    "            \n",
    "            #2. Set global weights of this training round to agent (loads the weights of last training)\n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/ddpg/cluster_{cluster_number}/FLround{best_federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            tf_agent = set_weights_to_ddpg_agent(tf_ddpg_agent, model_dir)\n",
    "\n",
    "            #3. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            iterator, collect_driver, time_step, policy_state = setup_rl_training_pipeline(\n",
    "                tf_ddpg_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,\n",
    "                collect_policy, initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #4. Setup wandb logging\n",
    "            artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{round}\", num_iterations=num_iterations)\n",
    "            \n",
    "            #5. Train, evaluate agent and store weights\n",
    "            result_df, metrics = agent_training_and_evaluation(global_step, num_test_iterations, collect_driver, \n",
    "                time_step, policy_state, iterator, tf_ddpg_agent, eval_policy, building_index, result_df, eval_interval, environments)\n",
    "            \n",
    "            #6. End and log wandb\n",
    "            end_and_log_wandb(metrics, artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "result_df.rename(columns={'Total Profit': 'Profit'}, inplace=True)\n",
    "result_df['Setup'] = f'cluster{num_clusters}'\n",
    "result_df.index.name = 'Building_nr'\n",
    "result_df.reset_index(inplace=True, drop=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "result_df.to_csv(f'results/results_DDPG_FL_clusters{num_clusters}_Emissions.csv', index=False)\n",
    "print(\"Final reuslt - clusters \", num_clusters, \" Profit: \", result_df[\"Profit\"].sum(), \" Emissions: \", result_df[\"Final Emissions\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_telegram_message(bot_token, chat_id, message):\n",
    "    \"\"\"Send a message to a Telegram chat via the Bot API.\"\"\"\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    payload = {\n",
    "        \"chat_id\": chat_id,\n",
    "        \"text\": message,\n",
    "        \"parse_mode\": \"Markdown\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Use the function\n",
    "bot_token = os.getenv('TELEGRAM_BOT_TOKEN')\n",
    "chat_id = os.getenv('TELEGRAM_CHAT_ID')\n",
    "message = f\"Script ist fertig am PC .81! DDPG FL Emissions\"\n",
    "\n",
    "result = send_telegram_message(bot_token, chat_id, message)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
